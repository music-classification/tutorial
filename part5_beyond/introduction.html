
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Introduction &#8212; Music Classification: Beyond Supervised Learning, Towards Real-world Applications</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet" />
  <link href="../_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.1c5a1a01449ed65a7b51.js">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script>
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Methods for Self-Supervised Learning" href="methods.html" />
    <link rel="prev" title="Semi-Supervised Learning" href="../part4_beyond/semi-supervised-learning.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
      
      
      <h1 class="site-logo" id="site-title">Music Classification: Beyond Supervised Learning, Towards Real-world Applications</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <p class="caption" role="heading">
 <span class="caption-text">
  The Basics
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../part1_intro/what-is-music-classification.html">
   What is Music Classification?
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../part2_basics/input-representations.html">
   Input Representations
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../part2_basics/dataset.html">
   Datasets
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../part2_basics/problem-formulation.html">
   Problem Formulation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../part2_basics/evaluation.html">
   Evaluation
  </a>
 </li>
</ul>
<p class="caption" role="heading">
 <span class="caption-text">
  Supervised Learning
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../part3_supervised/introduction.html">
   Introduction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../part3_supervised/architectures.html">
   Architectures
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../part3_supervised/data-augmentation.html">
   Audio Data Augmentations
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../part3_supervised/tutorial.html">
   PyTorch tutorial
  </a>
 </li>
</ul>
<p class="caption" role="heading">
 <span class="caption-text">
  Semi-supervised Learning
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../part4_beyond/introduction.html">
   Beyond Supervision
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../part4_beyond/transfer-learning.html">
   Transfer Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../part4_beyond/semi-supervised-learning.html">
   Semi-Supervised Learning
  </a>
 </li>
</ul>
<p class="caption" role="heading">
 <span class="caption-text">
  Self-supervised Learning
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Introduction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="methods.html">
   Methods for Self-Supervised Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="self-supervised-learning.html">
   PyTorch Tutorial
  </a>
 </li>
</ul>
<p class="caption" role="heading">
 <span class="caption-text">
  Towards Real-world Applications
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../part7_towards/mlops.html">
   MLOps
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../part7_towards/underexplored-problems.html">
   Under-Explored Problems in Academia
  </a>
 </li>
</ul>
<p class="caption" role="heading">
 <span class="caption-text">
  Conclusion
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../part8_conclusion/_intro.html">
   Conclusion
  </a>
 </li>
</ul>
<p class="caption" role="heading">
 <span class="caption-text">
  Resources
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../references.html">
   References
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/part5_beyond/introduction.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/music-classification/tutorial"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   Introduction
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#pre-training">
   Pre-training
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#self-supervised-learning">
   Self-supervised learning
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#should-i-use-self-supervised-learning">
   Should I use self-supervised learning?
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="introduction">
<h1>Introduction<a class="headerlink" href="#introduction" title="Permalink to this headline">¶</a></h1>
<p>Supervised learning of deep neural networks has seen many breakthroughs in music information retrieval. Across tasks like music classification, to source seperation or music recommendation, large neural networks that use a supervised optimization scheme have reached state-of-the-art results by way of using large, human-annotated datasets.</p>
<p>These large parameterised networks are data-hungry; they require many independent and identically distributed (i.i.d.) datapoints to generalize well in the task they are trained on. Especially in music, it can be hard to manually annotate, and the annotations often suffer from a single sources of truth. There is no single oracle: depending on the context, music theoretical background and cultural background, a song’s analysis can yield different results. In this chapter we observe a machine learning method that attempts to learn from unlabeled i.i.d. datapoints: self-supervised learning. We will first consider the term pre-training, how it is linked to self-supervised learning and its inherent caveats. Then, we will introduce the concept of self-supervised learning and review some key papers in this line of work at this moment of writing (October 2021).</p>
</div>
<div class="section" id="pre-training">
<h1>Pre-training<a class="headerlink" href="#pre-training" title="Permalink to this headline">¶</a></h1>
<p>The weights of neural networks have to be initialized before commencing the training on a target task. This initialization currently does not hold any apriori knowledge on the task at hand. To gain the weights that belong to a global minimum in our task is not an easy feat currently, especially for smaller, annotated datasets. However, we can choose to pre-train our network on a large annotated dataset to inject some information into the weights of our network, to help it steer our optimization scheme in the direction of our global minimum. This increasingly popular way to learn embeddings from large datasets of audio, and use these to train more shallow classifiers on smaller datasets, is referred to as pre-training.</p>
<p>However, pre-training also yields many caveats that have to be considered. Music datasets can be very biased towards certain concepts: they are represented more often and this will be picked up by our machine learning models. Even though we cannot clearly observe the bias by inspecting the weights of a trained network, it is now embedded in the pre-trained weights and will transfer downstream.</p>
<p>Also, the weights from a network trained on a different audio task often do not transfer well. When we use the pre-trained weights of a network that is trained on speech signals, one could make a clear argument why these weights are not helpful when our downstream task is to classify music.</p>
<p>Another challenge to consider, is that rare musical concepts (obviously) appear less in labeled datasets. In order to scale to these rarer concepts, we need a lot more data to account for this. This is generally known as the “long tail problem”, which is named after the data distribution we obtain when analyzing concepts in a dataset.</p>
</div>
<div class="section" id="self-supervised-learning">
<h1>Self-supervised learning<a class="headerlink" href="#self-supervised-learning" title="Permalink to this headline">¶</a></h1>
<p>In self-supervised learning, we obtain a supervisory signal from the data by leveraging its underlying structure. Generally, this can be done on the data itself, or in the space of the data representations. For example, we can predict part of the data from other parts of the data. Or, we can predict the future from events that occured in the past. In short - we predict the occluded from the visible, and we can control what events to occlude. Perhaps one task already sounds familiar and almost analogous: language modeling.</p>
<p>Within the last two years, many different self-supervised methods have been proposed, in particular for vision tasks, and resulted in great improvements over supervised methods when labeled datapoints are scarce. Recently, they even started to perform better than equivalent networks trained in a supervised manner.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><strong>Learning scheme</strong></p>
<p>It is worth visiting the general learning scheme of this line of work:</p>
<ol class="simple">
<li><p>First, we pre-train a neural network using a self-supervised objective (the pretext task).</p></li>
<li><p>In order to test the effectiveness of the learned representations, the pre-trained networks’ weights are “frozen”, and;</p></li>
<li><p>A linear evaluation on (part of) the supervised dataset is performed to compare against existing benchmarks.</p></li>
</ol>
<p>The linear evaluation scheme involves training a supervised linear classifier (a fully-connected layer followed by a softmax) using the representations extracted from the self-supervised network, and (a subset of) the labels associated with the data.</p>
</div>
</div>
<div class="section" id="should-i-use-self-supervised-learning">
<h1>Should I use self-supervised learning?<a class="headerlink" href="#should-i-use-self-supervised-learning" title="Permalink to this headline">¶</a></h1>
<p>Self-supervised learning can be beneficial in the following situations:</p>
<ul class="simple">
<li><p>The amount of labeled data available is scarce, and you do not want to sacrifice the size, and the expressivity, of your model.</p></li>
<li><p>Create more general-purpose representations that are not tightly coupled with a single use case, and can be used for multiple downstream tasks.</p></li>
<li><p>Improve the robustness of your network.</p></li>
</ul>
<p>You should take these considerations into account:</p>
<ul class="simple">
<li><p>A pre-trained model will have weights that reflect (and augment!) the biases embedded in a dataset.</p></li>
<li><p>The pretext task used as the self-supervised learning objective is important to analyze and reflect on, as it can yield many assumptions for the downstream task.</p></li>
</ul>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./part5_beyond"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
            



<div class='prev-next-bottom'>
    
    <div id="prev">
        <a class="left-prev" href="../part4_beyond/semi-supervised-learning.html" title="previous page">
            <i class="prevnext-label fas fa-angle-left"></i>
            <div class="prevnext-info">
                <p class="prevnext-label">previous</p>
                <p class="prevnext-title">Semi-Supervised Learning</p>
            </div>
        </a>
    </div>
     <div id="next">
        <a class="right-next" href="methods.html" title="next page">
            <div class="prevnext-info">
                <p class="prevnext-label">next</p>
                <p class="prevnext-title">Methods for Self-Supervised Learning</p>
            </div>
            <i class="prevnext-label fas fa-angle-right"></i>
        </a>
     </div>

</div>
        
        </div>
    </div>
    <footer class="footer">
    <div class="container">
      <p>
        
          By The Jupyter Book community<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
  </body>
</html>